{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT8yvSmyAkahyBEO6n8Go+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernandes666/Projeto_Da_Imersao-----ChatBot_Suporte_Emocional/blob/main/Assistente_Emocional_Virtual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **CHATBOT DE SUPORTE EMOCIONAL**\n"
      ],
      "metadata": {
        "id": "MqowU2LZ9mHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### O programa abaixo analisará o texto inserido pelo usuário e verificará se ele contêm emoções positivas ou negativas. A partir disso, ele dará uma resposta de acordo com o tipo de emoção."
      ],
      "metadata": {
        "id": "-ow8izjiDVLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importação da biblioteca google-generativeai**"
      ],
      "metadata": {
        "id": "3huDI1Lc6qiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3SvGznctZy5"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco de configuração da API**"
      ],
      "metadata": {
        "id": "StYqmexx66e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a chave da API do Google (substitua pela sua chave real)\n",
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "xPFAMAH26MQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco de definição do modelo**"
      ],
      "metadata": {
        "id": "HTwudhHO7NGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o modelo Gemini Pro a ser utilizado\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "37JJGjDA6MhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco de definição da função para gerar respostas**"
      ],
      "metadata": {
        "id": "z1G9oXUs7g3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(texto_usuario):\n",
        "    \"\"\"Gera uma resposta do Gemini Pro com base no texto do usuário.\"\"\"\n",
        "    # Chama o modelo para gerar conteúdo\n",
        "    response = model.generate_content(\n",
        "        texto_usuario,  # Passa o texto do usuário como entrada para o modelo\n",
        "        generation_config={'temperature': 0.7, 'max_output_tokens': 500000}  # Configura parâmetros de geração\n",
        "    )\n",
        "    # Retorna o texto da resposta gerada\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "6Kl6vMjG6Msi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco de definição da função para processar sentimento**"
      ],
      "metadata": {
        "id": "VJIyN4W_7s9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processar_sentimento(texto):\n",
        "    \"\"\"Analisa o sentimento do texto do usuário. (Implementação simplificada)\"\"\"\n",
        "\n",
        "    # Lista de palavras-chave negativas para análise de sentimento\n",
        "    palavras_chave_negativas = [\"triste\", \"ansioso\", \"deprimido\", \"solitário\"]\n",
        "\n",
        "    # Verifica se alguma palavra-chave negativa está presente no texto\n",
        "    if any(palavra in texto for palavra in palavras_chave_negativas):\n",
        "        # Se sim, retorna \"negativo\"\n",
        "        return \"negativo\"\n",
        "    # Caso contrário, retorna \"positivo\"\n",
        "    return \"positivo\""
      ],
      "metadata": {
        "id": "Aehhi_477tLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco de interação com o usuário**"
      ],
      "metadata": {
        "id": "U9tjdEz38BKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mensagem inicial para o usuário\n",
        "print(\"Olá! Sou um chatbot de suporte emocional. Como você está se sentindo hoje?\")\n",
        "\n",
        "# Loop principal do chatbot\n",
        "while True:\n",
        "    # Obtém a entrada do usuário\n",
        "    texto_usuario = input(\"Você: \")\n",
        "    # Verifica se o usuário deseja sair\n",
        "    if texto_usuario.lower() == 'sair':\n",
        "        # Se sim, encerra o loop\n",
        "        break\n",
        "    # Processa o sentimento do texto do usuário\n",
        "    sentimento = processar_sentimento(texto_usuario)\n",
        "    # Define o prompt para o modelo com base no sentimento\n",
        "    if sentimento == \"negativo\":\n",
        "        prompt = f\"Por favor, ofereça palavras de conforto e apoio para alguém que está se sentindo '{texto_usuario}'.\"\n",
        "    else:\n",
        "        prompt = f\"Responda de forma amigável e encorajadora a alguém que está se sentindo '{texto_usuario}'.\"\n",
        "    # Gera uma resposta utilizando o modelo\n",
        "    resposta = gerar_resposta(prompt)\n",
        "    # Exibe a resposta do chatbot\n",
        "    print(\"Chatbot:\", resposta)"
      ],
      "metadata": {
        "id": "Ox8E3Suk8BXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}